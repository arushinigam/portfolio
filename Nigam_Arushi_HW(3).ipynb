{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arushi Nigam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statistics\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c)i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurtosis, Mean, standard deviation, maximum, minimum, skewness, frequencies, quantiles/quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c)ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>min2</th>\n",
       "      <th>min3</th>\n",
       "      <th>min4</th>\n",
       "      <th>min5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max1</th>\n",
       "      <th>max2</th>\n",
       "      <th>max3</th>\n",
       "      <th>max4</th>\n",
       "      <th>...</th>\n",
       "      <th>1st quart5</th>\n",
       "      <th>1st quart6</th>\n",
       "      <th>3rd quart1</th>\n",
       "      <th>3rd quart2</th>\n",
       "      <th>3rd quart3</th>\n",
       "      <th>3rd quart4</th>\n",
       "      <th>3rd quart5</th>\n",
       "      <th>3rd quart6</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Test or Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>29.50</td>\n",
       "      <td>7.23</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>bending1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>29.50</td>\n",
       "      <td>5.76</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>1.1450</td>\n",
       "      <td>34.50</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>bending1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>29.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>...</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>bending1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>5.15</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>24.3725</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>36.33</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>bending1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>2.83</td>\n",
       "      <td>28.25</td>\n",
       "      <td>6.42</td>\n",
       "      <td>...</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>22.0625</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>bending1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>19.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.33</td>\n",
       "      <td>14.67</td>\n",
       "      <td>23.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>2.0500</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>6.1050</td>\n",
       "      <td>17.2700</td>\n",
       "      <td>4.2600</td>\n",
       "      <td>18.25</td>\n",
       "      <td>4.3225</td>\n",
       "      <td>walking</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.50</td>\n",
       "      <td>13.47</td>\n",
       "      <td>22.25</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>2.1575</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>5.9700</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>4.3900</td>\n",
       "      <td>17.75</td>\n",
       "      <td>4.5650</td>\n",
       "      <td>walking</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>19.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>12.47</td>\n",
       "      <td>22.67</td>\n",
       "      <td>8.34</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>2.1600</td>\n",
       "      <td>37.8125</td>\n",
       "      <td>5.8000</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>4.1100</td>\n",
       "      <td>17.75</td>\n",
       "      <td>4.3350</td>\n",
       "      <td>walking</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>23.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.25</td>\n",
       "      <td>14.82</td>\n",
       "      <td>24.25</td>\n",
       "      <td>9.90</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>5.9325</td>\n",
       "      <td>17.2500</td>\n",
       "      <td>4.1900</td>\n",
       "      <td>18.00</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>walking</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>19.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.43</td>\n",
       "      <td>44.00</td>\n",
       "      <td>13.86</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.10</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>5.9000</td>\n",
       "      <td>17.3300</td>\n",
       "      <td>4.0375</td>\n",
       "      <td>17.75</td>\n",
       "      <td>4.3750</td>\n",
       "      <td>walking</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     min1  min2  min3  min4   min5  min6   max1   max2   max3  max4  ...  \\\n",
       "0   37.25   0.0  4.00   0.0  27.25  0.00  45.00   1.30  29.50  7.23  ...   \n",
       "1   38.00   0.0  2.00   0.0  27.67  0.00  45.67   1.22  29.50  5.76  ...   \n",
       "2   35.00   0.0  6.50   0.0  29.00  0.00  47.40   1.70  29.75  4.44  ...   \n",
       "3   33.00   0.0  8.50   0.0  20.00  0.00  47.75   3.00  30.00  5.15  ...   \n",
       "4   33.00   0.0  3.00   0.0  23.67  0.00  45.75   2.83  28.25  6.42  ...   \n",
       "..    ...   ...   ...   ...    ...   ...    ...    ...    ...   ...  ...   \n",
       "83  19.50   0.0  7.33   0.0   6.33  0.00  45.33  14.67  23.25  9.00  ...   \n",
       "84  19.75   0.0  6.25   0.0   6.25  0.00  45.50  13.47  22.25  9.00  ...   \n",
       "85  19.50   0.0  7.00   0.0   7.00  0.00  46.00  12.47  22.67  8.34  ...   \n",
       "86  23.50   0.0  6.67   0.0   5.50  0.00  46.25  14.82  24.25  9.90  ...   \n",
       "87  19.25   0.0  6.00   0.0   4.67  0.43  44.00  13.86  22.75  9.10  ...   \n",
       "\n",
       "    1st quart5  1st quart6  3rd quart1  3rd quart2  3rd quart3  3rd quart4  \\\n",
       "0      33.0000      0.0000     42.0000      0.5000     23.2500      1.1200   \n",
       "1      32.0000      0.0000     43.6700      0.5000     22.2500      1.1450   \n",
       "2      35.3625      0.0000     45.0000      0.5000     24.0000      0.8300   \n",
       "3      30.4575      0.0000     45.0000      1.1200     24.3725      1.3000   \n",
       "4      28.4575      0.0000     42.7500      0.7100     22.0625      1.1200   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "83     13.7300      2.0500     37.0000      6.1050     17.2700      4.2600   \n",
       "84     13.5000      2.1575     38.0000      5.9700     17.0000      4.3900   \n",
       "85     14.0000      2.1600     37.8125      5.8000     17.0000      4.1100   \n",
       "86     13.7500      2.1700     38.2500      5.9325     17.2500      4.1900   \n",
       "87     13.7300      2.1200     38.0000      5.9000     17.3300      4.0375   \n",
       "\n",
       "    3rd quart5  3rd quart6    Labels  Test or Train  \n",
       "0        36.00      1.3000  bending1           test  \n",
       "1        34.50      1.3000  bending1           test  \n",
       "2        36.50      0.9400  bending1          train  \n",
       "3        36.33      1.0000  bending1          train  \n",
       "4        31.25      0.5000  bending1          train  \n",
       "..         ...         ...       ...            ...  \n",
       "83       18.25      4.3225   walking          train  \n",
       "84       17.75      4.5650   walking          train  \n",
       "85       17.75      4.3350   walking          train  \n",
       "86       18.00      4.5000   walking          train  \n",
       "87       17.75      4.3750   walking          train  \n",
       "\n",
       "[88 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hold all of the mins for each series\n",
    "min1 = [];\n",
    "min2 = [];\n",
    "min3 = [];\n",
    "min4 = [];\n",
    "min5 = [];\n",
    "min6 = [];\n",
    "\n",
    "# Hold all of the maxs for each series\n",
    "max1 = [];\n",
    "max2 = [];\n",
    "max3 = [];\n",
    "max4 = [];\n",
    "max5 = [];\n",
    "max6 = [];\n",
    "\n",
    "# Hold all of the means for each series\n",
    "mean1 = [];\n",
    "mean2 = [];\n",
    "mean3 = [];\n",
    "mean4 = [];\n",
    "mean5 = [];\n",
    "mean6 = [];\n",
    "\n",
    "# Hold all of the medians for each series\n",
    "median1 = [];\n",
    "median2 = [];\n",
    "median3 = [];\n",
    "median4 = [];\n",
    "median5 = [];\n",
    "median6 = [];\n",
    "\n",
    "# Hold all of the standard deviations for each series\n",
    "sd1 = [];\n",
    "sd2 = [];\n",
    "sd3 = [];\n",
    "sd4 = [];\n",
    "sd5 = [];\n",
    "sd6 = [];\n",
    "\n",
    "# Hold all of the 1st quartiles for each series\n",
    "fq1 = [];\n",
    "fq2 = [];\n",
    "fq3 = [];\n",
    "fq4 = [];\n",
    "fq5 = [];\n",
    "fq6 = [];\n",
    "\n",
    "# Hold all of the 3rd quartiles for each series\n",
    "tq1 = [];\n",
    "tq2 = [];\n",
    "tq3 = [];\n",
    "tq4 = [];\n",
    "tq5 = [];\n",
    "tq6 = [];\n",
    "\n",
    "labels = [];\n",
    "tortr = [];\n",
    "\n",
    "# dftest = pd.read_csv('AReM/bending1/dataset1.csv')\n",
    "# q = dftest.quantile([0.25, 0.75])\n",
    "# print(q)\n",
    "# print(q['avg_rss12'].iat[1])\n",
    "\n",
    "# -------- Bending1 Folder ------------\n",
    "for i in range(1,8):\n",
    "    path = '../data/AReM/bending1/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('bending1')\n",
    "\n",
    "    if i < 3:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "        \n",
    "\n",
    "\n",
    "# -------- Bending2 Folder ------------\n",
    "for i in range(1,7):\n",
    "    path = '../data/AReM/bending2/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('bending2')\n",
    "\n",
    "    if i < 3:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "\n",
    "# -------- Cycling Folder ------------\n",
    "for i in range(1,16):\n",
    "    path = '../data/AReM/cycling/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('cycling')\n",
    "\n",
    "    if i < 4:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "# -------- Lying Folder ------------\n",
    "for i in range(1,16):\n",
    "    path = '../data/AReM/lying/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('lying')\n",
    "\n",
    "    if i < 4:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "# -------- Standing Folder ------------\n",
    "for i in range(1,16):\n",
    "    path = '../data/AReM/standing/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('standing')\n",
    "\n",
    "    if i < 4:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "# -------- Sitting Folder ------------\n",
    "for i in range(1,16):\n",
    "    path = '../data/AReM/sitting/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('sitting')\n",
    "\n",
    "    if i < 4:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "# -------- Walking Folder ------------\n",
    "for i in range(1,16):\n",
    "    path = '../data/AReM/walking/dataset' + str(i) + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    mins = df.min()\n",
    "    min1.append(mins[1])\n",
    "    min2.append(mins[2])\n",
    "    min3.append(mins[3])\n",
    "    min4.append(mins[4])\n",
    "    min5.append(mins[5])\n",
    "    min6.append(mins[6])\n",
    "    \n",
    "    maxs = df.max()\n",
    "    max1.append(maxs[1])\n",
    "    max2.append(maxs[2])\n",
    "    max3.append(maxs[3])\n",
    "    max4.append(maxs[4])\n",
    "    max5.append(maxs[5])\n",
    "    max6.append(maxs[6])\n",
    "    \n",
    "    means = df.mean()\n",
    "    mean1.append(means[1])\n",
    "    mean2.append(means[2])\n",
    "    mean3.append(means[3])\n",
    "    mean4.append(means[4])\n",
    "    mean5.append(means[5])\n",
    "    mean6.append(means[6])\n",
    "    \n",
    "    medians = df.median()\n",
    "    median1.append(medians[1])\n",
    "    median2.append(medians[2])\n",
    "    median3.append(medians[3])\n",
    "    median4.append(medians[4])\n",
    "    median5.append(medians[5])\n",
    "    median6.append(medians[6])\n",
    "\n",
    "    sds = df.std()\n",
    "    sd1.append(sds[1])\n",
    "    sd2.append(sds[2])\n",
    "    sd3.append(sds[3])\n",
    "    sd4.append(sds[4])\n",
    "    sd5.append(sds[5])\n",
    "    sd6.append(sds[6])\n",
    "    \n",
    "    quants = df.quantile([0.25, 0.75])\n",
    "    fq1.append(quants['avg_rss12'].iat[0])\n",
    "    fq2.append(quants['var_rss12'].iat[0])\n",
    "    fq3.append(quants['avg_rss13'].iat[0])\n",
    "    fq4.append(quants['var_rss13'].iat[0])\n",
    "    fq5.append(quants['avg_rss23'].iat[0])\n",
    "    fq6.append(quants['var_rss23'].iat[0])\n",
    "\n",
    "    tq1.append(quants['avg_rss12'].iat[1])\n",
    "    tq2.append(quants['var_rss12'].iat[1])\n",
    "    tq3.append(quants['avg_rss13'].iat[1])\n",
    "    tq4.append(quants['var_rss13'].iat[1])\n",
    "    tq5.append(quants['avg_rss23'].iat[1])\n",
    "    tq6.append(quants['var_rss23'].iat[1])\n",
    "\n",
    "    labels.append('walking')\n",
    "\n",
    "    if i < 4:\n",
    "        tortr.append(\"test\")\n",
    "    else:\n",
    "        tortr.append(\"train\")\n",
    "\n",
    "\n",
    "# Creating dataframe containing k-values, training errors, and testing errors\n",
    "tdf = pd.DataFrame(zip(min1,min2,min3,min4,min5,min6,max1,max2,max3,max4,max5,max6,mean1,mean2,mean3,mean4,mean5,mean6,median1,median2,median3,median4,median5,median6,sd1,sd2,sd3,sd4,sd5,sd6,fq1,fq2,fq3,fq4,fq5,fq6,tq1,tq2,tq3,tq4,tq5,tq6,labels,tortr), columns =['min1','min2','min3','min4','min5','min6','max1','max2','max3','max4','max5','max6','mean1','mean2','mean3','mean4','mean5','mean6','median1','median2','median3','median4','median5','median6','sd1','sd2','sd3','sd4','sd5','sd6','1st quart1','1st quart2','1st quart3','1st quart4','1st quart5','1st quart6','3rd quart1','3rd quart2','3rd quart3','3rd quart4','3rd quart5','3rd quart6','Labels','Test or Train'])\n",
    "\n",
    "# Plotting training and testing errors\n",
    "tdf.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c)iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St. Dev min1 : 9.515445066931843\n",
      "min1 ConfidenceInterval(low=8.315060598697327, high=10.818136202207302)\n",
      "St. Dev min2 : 0.0\n",
      "min2 ConfidenceInterval(low=0.0, high=0.0)\n",
      "St. Dev min3 : 2.9396159844182215\n",
      "min3 ConfidenceInterval(low=2.789573426068866, high=3.1378407817805436)\n",
      "St. Dev min4 : 0.0\n",
      "min4 ConfidenceInterval(low=0.0, high=0.0)\n",
      "St. Dev min5 : 6.0891065514606755\n",
      "min5 ConfidenceInterval(low=4.724774622669977, high=7.738063269559521)\n",
      "St. Dev min6 : 0.045576965827593074\n",
      "min6 ConfidenceInterval(low=0.013124961748951322, high=0.09115393165518615)\n",
      "St. Dev max1 : 4.36932238296287\n",
      "max1 ConfidenceInterval(low=3.4521163040451173, high=5.416049652177078)\n",
      "St. Dev max2 : 5.033881679163114\n",
      "max2 ConfidenceInterval(low=4.692112739093007, high=5.471538612273188)\n",
      "St. Dev max3 : 4.8473579111726695\n",
      "max3 ConfidenceInterval(low=4.2530810835033135, high=5.545167459982907)\n",
      "St. Dev max4 : 2.171183073234498\n",
      "max4 ConfidenceInterval(low=1.9935769991853887, high=2.383588546849202)\n",
      "St. Dev max5 : 5.7085244261061385\n",
      "max5 ConfidenceInterval(low=4.89151924579762, high=6.718224284938212)\n",
      "St. Dev max6 : 2.50456803477282\n",
      "max6 ConfidenceInterval(low=2.2669221334288583, high=2.772665313816803)\n",
      "St. Dev mean1 : 5.305314461239687\n",
      "mean1 ConfidenceInterval(low=4.76235475618383, high=5.945942668021819)\n",
      "St. Dev mean2 : 1.565194252074566\n",
      "mean2 ConfidenceInterval(low=1.433846018175694, high=1.7436237500681613)\n",
      "St. Dev mean3 : 3.985540173028038\n",
      "mean3 ConfidenceInterval(low=3.5104007849681684, high=4.567896628618345)\n",
      "St. Dev mean4 : 1.1594695120976577\n",
      "mean4 ConfidenceInterval(low=1.1039141787335642, high=1.2472225736205853)\n",
      "St. Dev mean5 : 5.643253378646845\n",
      "mean5 ConfidenceInterval(low=4.587301692224756, high=6.870527867036801)\n",
      "St. Dev mean6 : 1.1482317454684936\n",
      "mean6 ConfidenceInterval(low=1.088098750826995, high=1.2416287876511702)\n",
      "St. Dev median1 : 5.409056425357996\n",
      "median1 ConfidenceInterval(low=4.846685763348054, high=6.053156317565297)\n",
      "St. Dev median2 : 1.4041971241720508\n",
      "median2 ConfidenceInterval(low=1.2730338496310472, high=1.5758462140907248)\n",
      "St. Dev median3 : 4.013396722341803\n",
      "median3 ConfidenceInterval(low=3.518584370003585, high=4.617464332708629)\n",
      "St. Dev median4 : 1.139058054228987\n",
      "median4 ConfidenceInterval(low=1.0844052848529806, high=1.2276528490240937)\n",
      "St. Dev median5 : 5.780655201421558\n",
      "median5 ConfidenceInterval(low=4.6955740151885745, high=7.080083273085398)\n",
      "St. Dev median6 : 1.080283538057551\n",
      "median6 ConfidenceInterval(low=1.018582674777678, high=1.1736047307684188)\n",
      "St. Dev sd1 : 1.7620555751491025\n",
      "sd1 ConfidenceInterval(low=1.5831537025633298, high=1.9634654471537163)\n",
      "St. Dev sd2 : 0.8790677991268445\n",
      "sd2 ConfidenceInterval(low=0.821842611342418, high=0.9601999536334052)\n",
      "St. Dev sd3 : 0.941315857696776\n",
      "sd3 ConfidenceInterval(low=0.7657818370179299, high=1.1248006383761333)\n",
      "St. Dev sd4 : 0.45563061241860064\n",
      "sd4 ConfidenceInterval(low=0.4275841846827266, high=0.49209890899655834)\n",
      "St. Dev sd5 : 1.0190579837087281\n",
      "sd5 ConfidenceInterval(low=0.8263639988143336, high=1.2270476529167018)\n",
      "St. Dev sd6 : 0.5146680632623812\n",
      "sd6 ConfidenceInterval(low=0.4879758137431893, high=0.5529327471032489)\n",
      "St. Dev 1st quart1 : 6.118526249454473\n",
      "1st quart1 ConfidenceInterval(low=5.6344505541734184, high=6.6914573854987385)\n",
      "St. Dev 1st quart2 : 0.9409936333203218\n",
      "1st quart2 ConfidenceInterval(low=0.8530493505043089, high=1.0560294926032432)\n",
      "St. Dev 1st quart3 : 4.196608356067418\n",
      "1st quart3 ConfidenceInterval(low=3.707315317369331, high=4.7841781212080985)\n",
      "St. Dev 1st quart4 : 0.8388126951078969\n",
      "1st quart4 ConfidenceInterval(low=0.7913288657694884, high=0.9098366928790721)\n",
      "St. Dev 1st quart5 : 6.061727225339022\n",
      "1st quart5 ConfidenceInterval(low=4.970179305575866, high=7.351394986538974)\n",
      "St. Dev 1st quart6 : 0.754261365241397\n",
      "1st quart6 ConfidenceInterval(low=0.7053240658576958, high=0.8217522738035883)\n",
      "St. Dev 3rd quart1 : 5.109642753365408\n",
      "3rd quart1 ConfidenceInterval(low=4.417239349255205, high=5.902469228041961)\n",
      "St. Dev 3rd quart2 : 2.1131565277371136\n",
      "3rd quart2 ConfidenceInterval(low=1.9429586050439869, high=2.340665803498041)\n",
      "St. Dev 3rd quart3 : 4.1478580691355535\n",
      "3rd quart3 ConfidenceInterval(low=3.6386726155900693, high=4.7725936928046675)\n",
      "St. Dev 3rd quart4 : 1.543657928587387\n",
      "3rd quart4 ConfidenceInterval(low=1.4692974464242374, high=1.6627882928375366)\n",
      "St. Dev 3rd quart5 : 5.500200189394758\n",
      "3rd quart5 ConfidenceInterval(low=4.509890637453688, high=6.686413055294202)\n",
      "St. Dev 3rd quart6 : 1.514917579004774\n",
      "3rd quart6 ConfidenceInterval(low=1.4387411653132625, high=1.6369976619902336)\n"
     ]
    }
   ],
   "source": [
    "tdfcols = tdf.columns.tolist()\n",
    "for i in range(0,42):\n",
    "    data = (tdf[tdfcols[i]], )\n",
    "    print(\"St. Dev\", tdfcols[i], ':', np.std(data))        \n",
    "    cf = bootstrap(data, np.std, confidence_level=0.9, method='basic')\n",
    "    print(tdfcols[i], cf.confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(c)iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose mean, median, and standard deviation as these are extremely popular values used in statistics to help determine whether or not there is statistical significance. It would be good to get familiar with them in the long run. Also, looking at my confidence intervals, these three have interesting confidence intervals where some are very close and some are very far; so, it would be interesting to see whether that has any effect on my calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.) For the training set specifically, the cubic regression would have a lower RSS because it would try to fit every point better than the \n",
    "linear model, which could potentially lead to overfitting. Similar to how in class when we saw the train MSE vs. test MSE plot, as the \n",
    "degree of the model increased, the model started to overfit the data in the training set and thus the MSE started dropping.\n",
    "\n",
    "b.) For the test set specifically, the linear model would have lower RSS as the true model is linear and the closer we  are to the true model during testing, the lower the RSS will be as the difference between the actual y and the predicted y will be lower than the cubic regression model.\n",
    "\n",
    "c.) Even though we know the model is not linear, the cubic regression in the training set would still have a lower RSS similar to the reasoning in a. The model would try to fit each point more than the linear regression model in the training set. Similar to how in class when we saw the train MSE vs. test MSE plot, as the degree of the model increased, the model started to overfit the data in the training set and thus the MSE started dropping. \n",
    "\n",
    "d.) There is not enough information to tell because if the model is closer to cubic, than the cubic regression would have a lower RSS. If the model is closer to linear, than the linear model would have the lower RSS. Therefore, it cannot be said with certainty, which model would have the lower test RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "https://www.geeksforgeeks.org/accessing-elements-of-a-pandas-series/\n",
    "\n",
    "https://www.statology.org/pandas-standard-deviation/\n",
    "\n",
    "https://thispointer.com/get-first-value-of-a-column-in-pandas-dataframe/\n",
    "\n",
    "https://www.geeksforgeeks.org/python-append-multiple-lists-at-once/\n",
    "\n",
    "https://www.geeksforgeeks.org/python-standard-deviation-of-list/\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html\n",
    "\n",
    "https://pandas.pydata.org/docs/user_guide/merging.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsci552')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "714149b94df860ac6065d03a6b9e9090d187bab47473d63b239cc2644ed12507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
